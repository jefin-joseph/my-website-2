---
title: "Ipsum"
description: ""
slug: "ipsum"
image: pic10.jpg
keywords: ""
categories: 
    - ""
    - ""
date: 2017-10-31T21:28:43-05:00
draft: false
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(wbstats)
library(countrycode)
library(patchwork)
library(gganimate)
library(purrr)
library(gifski)
library(png)
library(infer)
```

Recall the TfL data on how many bikes were hired every single day. We
can get the latest data by running the following

```{r, get_tfl_data, cache=TRUE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

We can easily create a facet grid that plots bikes hired by month and
year since 2015

However, the challenge I want you to work on is to reproduce the
following two graphs.

The second one looks at percentage changes from the expected level of
weekly rentals. The two grey shaded rectangles correspond to Q2 (weeks
14-26) and Q4 (weeks 40-52).

For both of these graphs, you have to calculate the expected number of
rentals per week or month between 2016-2019 and then, see how each
week/month of 2020-2022 compares to the expected rentals. Think of the
calculation `excess_rentals = actual_rentals - expected_rentals`.

Should you use the mean or the median to calculate your expected
rentals? Why?

> We should use the mean to calculate the expected rentals. 
> From the distribution of rentals in past eight years, we could tell that the 
> distributions are closed. The distributions are closed to normal distribution 
> and the mean works perfectly well for a normal distribution. Furthermore, not 
> many outliers exists and the amount of data we use is huge and it can reduce 
> the effect of outliers. Some outliers are caused by events that could happen 
> again in the future. 

In creating your plots, you may find these links useful:

-   <https://ggplot2.tidyverse.org/reference/geom_ribbon.html>
-   <https://ggplot2.tidyverse.org/reference/geom_tile.html>
-   <https://ggplot2.tidyverse.org/reference/geom_rug.html>

```{r}
#Plot the monthly changes in TfL bike rentals
expected_bike_monthly <- bike %>%
  filter(year >= 2016 & year <= 2019) %>%
  group_by(month) %>%
  mutate(expected_rentals = mean(bikes_hired)) %>%
  select(expected_rentals, month)

actual_bike_monthly <- bike %>%
  filter(year >= 2017) %>%
  group_by(year, month) %>%
  mutate(actual_rentals = mean(bikes_hired))
  
actual_bike_monthly <- left_join(actual_bike_monthly, expected_bike_monthly, by = "month") %>%
  mutate(excess_rentals = (actual_rentals - expected_rentals)) %>%
  ggplot(aes(x = month, group = 1)) +
    geom_ribbon(aes(ymax = expected_rentals, 
                    ymin = pmin(excess_rentals, 0) + expected_rentals), 
                fill = "red", alpha = 0.4) +
    geom_ribbon(aes(ymax = actual_rentals, 
                    ymin = actual_rentals - pmax(excess_rentals, 0)),
                fill = "green", alpha = 0.4) +
    geom_line(aes(y = actual_rentals), size = 1) +
    geom_line(aes(y = expected_rentals), color = "blue", size = 1.3) +
    facet_wrap(~year) +
    labs(title = "Monthly changes in TfL bike rentals",
         subtitle = "Change from monthly average shown in blue and calculated between 2016-2019",
         caption = "Source: TfL, London Data Store",
         x = "Months",
         y = "Bike rentals") +
    theme_bw()

actual_bike_monthly
```
```{r}
rentals_weekly <- bike %>% 
  filter(year >= 2016) %>% 
  filter(year <= 2019) %>% 
  group_by(week) %>% 
  summarise(expected_rentals_weekly = mean(bikes_hired))
  
bike1 <- left_join(bike, rentals_weekly, "week")

percent <- bike1 %>% 
  filter(year >= 2017) %>% 
  filter(year <= 2022) %>% 
  filter(!(week >= 52 & year == 2022)) %>% 
  group_by(year, week) %>% 
  summarize(weekly_change = (mean(bikes_hired)-mean(expected_rentals_weekly))/
              mean(expected_rentals_weekly)) %>% 
  mutate(sign = case_when(weekly_change < 0 ~ "Negative",
                          weekly_change > 0 ~ "Positve"))

percent %>% 
  ggplot(aes(x = week, y = weekly_change)) +
  geom_line() +
  geom_ribbon(aes(ymax = pmax(0,weekly_change), ymin = 0), fill = "green", alpha = 0.2) +
  geom_ribbon(aes(ymax = 0, ymin = pmin(0, weekly_change)), fill = "red", alpha = 0.2) +
  facet_wrap(~ year) +
  geom_rug(mapping = aes(color = factor(sign)), sides = "b", show.legend = FALSE) +
  scale_color_manual(values = c("red", "green")) +
  scale_y_continuous(breaks = seq(-0.5, 1, 0.5),
                     limits = c(-0.6, 1),
                     labels = scales::percent) +
  scale_x_continuous(breaks = seq(13, 53, 13)) +
  labs(x = "week", y = NULL,
       title = "Weekly changes in TfL bike rentals",
       subtitle = "% change from weekly averages between 2016-2019",
       caption = "Source: TfL, London Data Store")
  
```